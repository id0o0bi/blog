---
layout: page
title:  "终于搞定 SimHash 算法"
date:   2018-03-19 08:40:02 +0800
category: tech algorithm lsh
permalink: simhash.html
---

[LSH 介绍(Wikipedia)](https://en.wikipedia.org/wiki/Locality-sensitive_hashing)  
[SimHash 原理及实现](http://blog.csdn.net/chenguolinblog/article/details/50830948)
<!--[SimHash 算法介绍](http://www.lanceyan.com/tech/arch/simhash_hamming_distance_similarity.html)-->

### 历史
需求来自于要为用户推荐与当前文章内容相近的文章  
考虑过的实现方案：
* 标签推荐 [准确度不高，同一标签下可能有千、万篇文章]
* 内容关键词推荐 [td-idf获取权重最高的关键词，然后使用相似度算法匹配最接近结果]
    1. 余弦相似度
    2. SimHash
* NLP [基于语义理解，获取更高的准确度，实现方法--未知]

产品经理 `龙某人` 推荐了余弦相似度算法  
并给我推荐了阮一峰大大的博客文章 [TF-IDF与余弦相似性的应用（二）：找出相似文章](http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html)  
* 多维向量相似的原理  
![cosine](/assets/post-images/simhash/bg2013032005.png)  
* 计算方法  
![formula](/assets/post-images/simhash/bg2013032007.png)

余弦相似度算法原理简单，准确度也比较高，实现起来相对容易，所以最早就用了这个算法.  
然而劣势也是很明显的：
* 数据结构复杂 (每篇文章生成特征向量，使用向量做比对)
* 获取相似内容所需计算复杂度高 (高维运算，计算量较大,几乎无法实时获取)

算是留了一个坑吧（此处 @`推荐了这个算法的产品经理`）

### 新算法
SimHash算法其实一开始我就遇到了。由于对原理不太理解，没敢用。。。  
上周有点时间，好好的看了一下，经过测试，准确度不比余弦相似度差(降维之后应该会损失一些精度)。  
对算法的理解和实现主要参考了上面CSDN博客里面的介绍。代码已经上了GitHub [SimHash](https://github.com/id0o0bi/SimHash)
效果演示：
```
gabriel@debian:~/Projects/SimHash$ /usr/local/php/bin/php test.php
001-002: 25  001-003: 25  001-004: 29  001-005: 27  001-006: 22  001-007: 30  001-008: 29  001-009: 24  001-010: 23  001-011: 28  001-012: 13
002-003: 22  002-004: 34  002-005: 32  002-006: 29  002-007: 31  002-008: 32  002-009: 19  002-010: 14  002-011: 23  002-012: 18
003-004: 38  003-005: 30  003-006: 23  003-007: 35  003-008: 32  003-009: 21  003-010: 18  003-011: 25  003-012: 26
004-005: 18  004-006: 21  004-007: 11  004-008: 14  004-009: 33  004-010: 38  004-011: 39  004-012: 32
005-006: 21  005-007: 19  005-008: 16  005-009: 27  005-010: 34  005-011: 27  005-012: 30
006-007: 22  006-008: 23  006-009: 26  006-010: 27  006-011: 26  006-012: 29
007-008: 11  007-009: 28  007-010: 39  007-011: 34  007-012: 33
008-009: 29  008-010: 34  008-011: 37  008-012: 26
009-010: 19  009-011: 22  009-012: 29
010-011: 27  010-012: 22
011-012: 27
```
上面是 [SimHash](https://github.com/id0o0bi/SimHash) 测试项目中12个文档输出的对比结果，部分摘自百度百家文章，部分摘自慕课网已有的相似文章列表，整体效果达到预期。
由于simhash算法原本是为了排重的，所以很多文章会说海明距离小于等于3才可以判定为相似。实际需求中，只要两篇文章讨论话题相近，这个海明距离还可以扩大一点。
就上面的案例来看，海明距离在 14 内的基本可以判定为相关文章了。

### 原理与实现摘
simhash作为locality sensitive hash（局部敏感哈希）的一种：其主要思想是降维，将高维的特征向量映射成低维的特征向量，通过两个向量的Hamming Distance来确定文章是否重复或者高度近似。
其中，Hamming Distance，又称汉明距离，在信息论中，两个等长字符串之间的汉明距离是两个字符串对应位置的不同字符的个数。也就是说，它就是将一个字符串变换成另外一个字符串所需要替换的字符个数。例如：1011101 与 1001001 之间的汉明距离是 2。至于我们常说的字符串编辑距离则是一般形式的汉明距离。  
如此，通过比较多个文档的simHash值的海明距离，可以获取它们的相似度。

simhash算法分为5个步骤：分词、hash、加权、合并、降维，具体过程如下所述：
1. 分词  
```
给定一段文本，进行分词，得到有效的特征向量。
```
2. hash  
```
通过hash函数计算各个特征向量的hash值，hash值为二进制数01组成的n-bit签名。
```
3. 加权  
```
在hash值的基础上，给所有特征向量进行加权，即W = Hash * weight，
且遇到1则hash值和权值正相乘，遇到0则hash值和权值负相乘。
```
4. 合并  
```
将上述各个特征向量的加权结果累加，变成只有一个序列串。
```
5. 降维  
```
对于n-bit签名的累加结果，如果大于0则置1，否则置0，从而得到该语句的simhash值，
最后我们便可以根据不同语句simhash的海明距离来判断它们的相似度。
```

流程图如下：  
![SimHash](/assets/post-images/simhash/687474703a2f2f646c2e69746579652e636f6d2f75706c6f61642f6174746163686d656e742f3433373432362f62616634323337382d653632352d333564322d396138392d3437313532346133353564382e6a7067.jpeg)

接下来还要应用的实践中去，暂定使用 mysql 存储文章的指纹信息，看一下查询效率，再做优化！


<!--来自于 Google 的Moses Charikar发表的一篇论文“detecting near-duplicates for web crawling”中提出了simhash算法，专门用来解决亿万级别的网页的去重任务。

simhash作为locality sensitive hash（局部敏感哈希）的一种：

其主要思想是降维，将高维的特征向量映射成低维的特征向量，通过两个向量的Hamming Distance来确定文章是否重复或者高度近似。  
其中，Hamming Distance，又称汉明距离，在信息论中，两个等长字符串之间的汉明距离是两个字符串对应位置的不同字符的个数。也就是说，它就是将一个字符串变换成另外一个字符串所需要替换的字符个数。例如：1011101 与 1001001 之间的汉明距离是 2。至于我们常说的字符串编辑距离则是一般形式的汉明距离。  
如此，通过比较多个文档的simHash值的海明距离，可以获取它们的相似度。-->